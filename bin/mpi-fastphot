#!/usr/bin/env python
"""
MPI wrapper for fastphot.

mpi-fastphot --mp 32 --tile 80608

"""
import pdb # for debugging

import os, time
import numpy as np

from desiutil.log import get_logger
log = get_logger()

def merge_fastphot(args, comm=None, outprefix='fastphot'):
    """Merge all the individual catalogs into a single large catalog. Runs only on
    rank 0.

    """
    import fitsio
    from astropy.io import fits
    from astropy.table import Table, vstack
    from fastspecfit.mpi import plan
    
    if comm is None:
        rank, size = 0, 1
    else:
        rank, size = comm.rank, comm.size

    outdir, _, outfiles, _, _ = plan(args, comm=comm, merge=True)

    t0 = time.time()
    out = vstack([Table(fitsio.read(outfile)) for outfile in outfiles])
    #out = Table(np.hstack([fitsio.read(outfile) for outfile in outfiles]))#[:5]]))
    log.info('Merging {} objects from {} {} files took {:.2f} min.'.format(
        len(out), len(outfiles), outprefix, (time.time()-t0)/60.0))

    tilemin, tilemax = out['TILEID'].min(), out['TILEID'].max()
    if tilemin == tilemax:
        tilesuffix = str(tilemin)
    else:
        tilesuffix = '{}-{}'.format(tilemin, tilemax)
        
    nightmin, nightmax = out['NIGHT'].min(), out['NIGHT'].max()
    if nightmin == nightmax:
        nightsuffix = str(nightmin)
    else:
        nightsuffix = '{}-{}'.format(nightmin, nightmax)

    hdr = fitsio.read_header(outfiles[0], ext='RESULTS') # assume they're all the same!

    outfile = os.path.join(outdir, '{}-{}-{}.fits'.format(outprefix, tilesuffix, nightsuffix))
    log.info('Writing {}'.format(outfile))
    hduprim = fits.PrimaryHDU()
    hduout = fits.convenience.table_to_hdu(out)
    hduout.header['EXTNAME'] = 'RESULTS'
    hduout.header['SPECPROD'] = hdr['SPECPROD']
    hx = fits.HDUList([hduprim, hduout])
    hx.writeto(outfile, overwrite=True)
    #out.write(outfile, overwrite=True)    
    
def run_fastphot(args, comm=None):

    import sys, subprocess
    from fastspecfit.mpi import backup_logs, plan

    if comm is None:
        rank, size = 0, 1
    else:
        rank, size = comm.rank, comm.size

    args.maxnodes = min(args.maxnodes, size)

    t0 = time.time()
    if rank == 0:
        log.info('Starting at {}'.format(time.asctime()))

    _, zbestfiles, outfiles, groups, grouptimes = plan(args, comm=comm)

    if rank == 0:
        log.info('Initial setup took {:.1f} sec'.format(time.time() - t0))

    sys.stdout.flush()
    if comm:
        zbestfiles = comm.bcast(zbestfiles, root=0)
        outfiles = comm.bcast(outfiles, root=0)
        groups = comm.bcast(groups, root=0)

    # all done
    if len(zbestfiles) == 0:
        return
        
    assert(len(groups) == size)
    assert(len(np.concatenate(groups)) == len(zbestfiles))

    #pixels = np.array([int(os.path.basename(os.path.dirname(x))) for x in zbestfiles])
    for ii in groups[rank]:
        log.info('Rank {} started at {}'.format(rank, time.asctime()))
        sys.stdout.flush()

        cmd = 'fastphot {} -o {} --mp {}'.format(zbestfiles[ii], outfiles[ii], args.mp)
        #cmd += ' --ntargets 16'

        if args.solve_vdisp:
            cmd += ' --solve-vdisp'

        logfile = outfiles[ii].replace('.fits', '.log')
        assert(logfile != outfiles[ii])

        log.info('  rank {}: {}'.format(rank, cmd))
        #log.info('LOGGING to {}'.format(logfile))
        sys.stdout.flush()

        if args.dry_run:
            continue

        try:
            t1 = time.time()
            if os.path.exists(logfile) and not args.overwrite:
                backup_logs(logfile)
            # memory leak?  Try making system call instead
            outdir = os.path.dirname(logfile)
            if not os.path.isdir(outdir):
                os.makedirs(outdir)
            with open(logfile, 'w') as mylog:
                err = subprocess.call(cmd.split(), stdout=mylog, stderr=mylog)
            dt1 = time.time() - t1
            if err == 0:
                log.info('  rank {} done in {:.2f} sec'.format(rank, dt1))
                if not os.path.exists(outfiles[ii]):
                    log.warning('  rank {} missing {}'.format(rank, outfiles[ii]))
            else:
                log.warning('  rank {} broke after {:.1f} sec with error code {}'.format(rank, dt1, err))
        except Exception as err:
            log.warning('  rank {} raised an exception'.format(rank))
            import traceback
            traceback.print_exc()

    log.info('  rank {} is done'.format(rank))
    sys.stdout.flush()

    if comm is not None:
        comm.barrier()

    if rank == 0 and not args.dry_run:
        for outfile in outfiles:
            if not os.path.exists(outfile):
                log.warning('Missing {}'.format(outfile))

        log.info('All done at {}'.format(time.asctime()))
        
def main():
    """Main wrapper on fastphot

    Currently only knows about SV1 observations.

    """
    import argparse    
    from fastspecfit.mpi import plan
    
    parser = argparse.ArgumentParser(formatter_class=argparse.ArgumentDefaultsHelpFormatter)
    parser.add_argument('--specprod', type=str, default='blanc', choices=['blanc', 'daily'], help='Spectroscopic production to process.')
    parser.add_argument('--spectype', type=str, default='deep-coadds', choices=['deep-coadds', 'night-coadds', 'exposures'],
                        help='Specify which type of spectra to process.')
    
    parser.add_argument('--tile', default=None, type=str, nargs='*', help='Tile(s) to process (ignored if spectype is exposures).')
    parser.add_argument('--night', default=None, type=str, nargs='*', help='Night(s) to process (ignored if spectype is exposures or deep-coadds).')
    
    parser.add_argument('--mp', type=int, default=1, help='Number of multiprocessing processes per MPI rank or node.')
    parser.add_argument('--maxnodes', type=int, default=256, help='maximum number of nodes to use')

    parser.add_argument('--solve-vdisp', action='store_true', help='Solve for the velocity disperion.')

    parser.add_argument('--merge', action='store_true', help='Merge all individual catalogs into one large file.')
    parser.add_argument('--overwrite', action='store_true', help='Overwrite any existing output files.')
    parser.add_argument('--plan', action='store_true', help='Plan how many nodes to use and how to distribute the targets.')
    parser.add_argument('--nompi', action='store_true', help='Do not use MPI parallelism.')
    parser.add_argument('--dry-run', action='store_true', help='Generate but do not run commands')

    args = parser.parse_args()

    if args.merge or args.nompi:
        comm = None
    else:
        try:
            from mpi4py import MPI
            comm = MPI.COMM_WORLD
        except ImportError:
            comm = None
            
    if args.merge:
        merge_fastphot(args, comm=comm, outprefix='fastphot')
    elif args.plan:
        plan(args, comm=comm, outprefix='fastphot')
    else:
        run_fastphot(args, comm=comm)

if __name__ == '__main__':
    main()

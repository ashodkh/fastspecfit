#!/usr/bin/env python

"""Validate the files generated by a given production.


"""
import os, argparse, pdb
from glob import glob
import numpy as np
import fitsio
import multiprocessing

from astropy.table import Table

from fastspecfit.io import DESI_ROOT_NERSC

def _targets_one_tile(args):
    """Multiprocessing wrapper."""
    return targets_one_tile(*args) 

def targets_one_tile(tileid, obstile, pottile):
    """Check one file.

    """
    print('  Checking tile {}'.format(tileid))
    # Check that the set of targetids are unique.
    try:
        assert(len(obstile) == len(np.unique(obstile['TARGETID'])))
        assert(len(pottile) == len(np.unique(pottile['TARGETID'])))
        
    # Check that every target in the targetphot file is also in the
    # targetphot-potential file.
        K = np.isin(obstile['TARGETID'], pottile['TARGETID'], assume_unique=True)
        assert(len(K) == len(obstile['TARGETID']))
    except:
        print('  Problem with tile {}!'.format(tileid))
        #pdb.set_trace()        

    # Now, ensure that the data stored in the potential and observed catalogs
    # *for the same objects* are identical.
    #I = np.isin(pottile['TARGETID'], obstile['TARGETID'], assume_unique=True)
    I = np.hstack([np.where(tid == pottile['TARGETID'])[0] for tid in obstile['TARGETID']])
    pot = pottile[I]
    assert(np.all(pot['TARGETID'] == obstile['TARGETID']))
    for col in pot.colnames:
        diff = np.where(pot[col] != obstile[col])[0]
        if len(diff) > 0:
            J = ~np.isnan(obstile[col][diff]) # need to check nan separately
            if np.sum(J) > 0:
                diff = diff[J]
                print(col, pot[col][diff].data, obstile[col][diff].data)

def fileinfo(filelist, specprod):

    dsurvey = {'cmx': 'Commissioning Survey', 'special': 'Special targets',
               'sv1': 'Survey Validation 1', 'sv2': 'Survey Validation 2',
               'sv3': 'Survey Validation 3', 'main': 'Main Survey',
               '{}.fits'.format(specprod): 'Stack of the preceding XX catalogs.'}

    nrows, szs = [], []
    for onefile in filelist:
        szs.append(os.stat(onefile).st_size)
        nrows.append(fitsio.FITS(onefile)[1].get_nrows())
    szs = np.array(szs)
    nrows = np.array(nrows)

    #srt = np.argsort(nrows)
    srt = np.arange(len(nrows))

    print('| File Name | File Size | Number of Targets | Notes |')
    print('|-----------|:---------:|:-----------------:|-------|')
    for onefile, nrow, sz in zip(filelist[srt], nrows[srt], szs[srt]):
        if sz > 1024 and sz < 1024**2:
            sz /= 1024
            unit = 'KB'
            fmt = ''
        elif sz > 1024**2 and sz < 1024**3:
            sz /= 1024**2
            unit = 'MB'
            fmt = ''
        else:
            sz /= 1024**3
            unit = 'GB'

        basefile = os.path.basename(onefile)
        survey = basefile.split('-')[2]
        #if survey == 'potential':
        #    survey = basefile.split('-')[2]
        notes = dsurvey[survey].replace('XX', str(len(filelist)-1))
            
        print('| {} | {:.3g} {} | {:,d} | {} |'.format(basefile, sz, unit, nrow, notes))

def main():

    p = argparse.ArgumentParser()
    p.add_argument('--specprod', type=str, required=True, help='output file prefix')
    p.add_argument('-o', '--outdir', type=str, default='.', help='output directory')    
    p.add_argument('--mp', type=int, default=1, help='number of multiprocessing cores')
    p.add_argument('--statistics', action='store_true', help='Do file statistics.')
    p.add_argument('--validate', action='store_true', help='Validate the files.')
    
    args = p.parse_args()

    subdir = 'healpix'
    outdir = os.path.join(args.outdir, args.specprod)

    desi_root = os.environ.get('DESI_ROOT', DESI_ROOT_NERSC)
    
    specprod_dir = os.path.join(desi_root, 'spectro', 'redux', args.specprod, subdir)

    # Do statistics.
    if args.statistics:

        for prefix in ['fastphot', 'fastspec']:
            surveyfiles = np.array(sorted(glob(os.path.join(outdir, 'catalogs', '{}-{}-*.fits'.format(prefix, args.specprod)))))
            fileinfo(surveyfiles, args.specprod)
            print()

    pdb.set_trace()
            
    # Validate files.
    if args.validate:
        for survey in surveys:
        #for survey in ['sv1']:
            print('Working on survey {}'.format(survey))
            obsfile = os.path.join(args.outdir, 'observed-targets', 'targetphot-{}-{}.fits'.format(survey, args.specprod))
            potfile = os.path.join(args.outdir, 'potential-targets', 'targetphot-potential-{}-{}.fits'.format(survey, args.specprod))
            obs = Table(fitsio.read(obsfile))
            print('Read {:,d} objects from {}'.format(len(obs), obsfile))
            pot = Table(fitsio.read(potfile))
            print('Read {:,d} objects from {}'.format(len(pot), potfile))

            #obs = obs[obs['TILEID'] == 80870]

            tileids = sorted(set(obs['TILEID']))
            print('Processing {} unique tiles'.format(len(tileids)))
            
            # Multiprocess over tiles
            mpargs = [[tileid, obs[obs['TILEID'] == tileid], pot[pot['TILEID'] == tileid]] for tileid in tileids]
                
            if args.mp > 1:
                with multiprocessing.Pool(args.mp) as P:
                    P.map(_targets_one_tile, mpargs)
            else:
                [targets_one_tile(*mparg) for mparg in mpargs]
        print()
            
if __name__ == '__main__':
    main()

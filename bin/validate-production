#!/usr/bin/env python

"""Validate the files generated by a given production.

validate-production --specprod fuji --mp 128 --statistics
validate-production --specprod guadalupe --mp 128 --statistics

"""
import os, argparse, pdb
from glob import glob
import numpy as np
import fitsio
import multiprocessing
from astropy.table import Table

from fastspecfit.io import DESI_ROOT_NERSC, _ZWarningMask
ZWarningMask = _ZWarningMask()

from desiutil.log import get_logger, DEBUG
log = get_logger()

def _check_one_catalog(args):
    """Multiprocessing wrapper."""
    return check_one_catalog(*args) 

def check_one_catalog(zcatfile, specprod):
    
    fastfile = zcatfile.replace('redux/{}/zcatalog/zpix-'.format(specprod), 'fastspecfit/{0}/catalogs/fastspec-{0}-'.format(specprod))
    
    log.info('Reading {}'.format(zcatfile))
    zcat = Table(fitsio.read(zcatfile, ext='ZCATALOG', columns=['TARGETID', 'Z', 'ZWARN', 'OBJTYPE']))
    I = np.where((zcat['Z'] > 0.001) * (zcat['OBJTYPE'] == 'TGT') * (zcat['ZWARN'] & ZWarningMask.NODATA == 0))[0]
    zcat = zcat[I]

    fast = Table(fitsio.read(fastfile, ext='METADATA', columns=['TARGETID', 'Z', 'Z_RR', 'ZWARN']))
    srt = np.hstack([np.where(zcat['TARGETID'] == tid)[0] for tid in fast['TARGETID']])
    zcat = zcat[srt]

    assert(len(zcat) == len(fast))

    for fcol, zcol in zip(['TARGETID', 'Z_RR', 'ZWARN'], ['TARGETID', 'Z', 'ZWARN']):
        try:
            assert(np.all(fast[fcol] == zcat[zcol]))
        except:
            log.warning('Assert failed on column {} in catalog {}'.format(fcol, fastfile))
            pdb.set_trace()

    zdiff = fast['Z'] != zcat['Z']
    if np.sum(zdiff) > 0:
        log.info('Found {:,d}/{:,d} ({:.4f}%) updated QSO redshifts in catalog {}'.format(
            np.sum(zdiff), len(fast), np.sum(zdiff)/len(fast), fastfile))
            
def fileinfo(filelist, sortbyrows=False):

    headers = ['File Name', 'File Size', 'Number of Targets']

    nrows, szs = [], []
    for onefile in filelist:
        szs.append(os.stat(onefile).st_size)
        nrows.append(fitsio.FITS(onefile)[1].get_nrows())
    szs = np.array(szs)
    nrows = np.array(nrows)

    if sortbyrows:
        srt = np.argsort(nrows)
    else:
        srt = np.arange(len(nrows))

    lines = []
    widths = np.array([len(header) for header in headers])
    for onefile, nrow, sz in zip(filelist[srt], nrows[srt], szs[srt]):
        if sz > 1024 and sz < 1024**2:
            sz /= 1024
            unit = 'KB'
            fmt = ''
        elif sz > 1024**2 and sz < 1024**3:
            sz /= 1024**2
            unit = 'MB'
            fmt = ''
        else:
            sz /= 1024**3
            unit = 'GB'

        sz = '{:.3g} {}'.format(sz, unit)

        basefile = os.path.basename(onefile)
        nrow = '{:,d}'.format(nrow)

        # get the widths
        oneline = []
        for ii, dd in enumerate([basefile, sz, nrow]):
            if len(dd) > widths[ii]:
                widths[ii] = len(dd)
            oneline.append(dd)

        lines.append(oneline)

    return widths, lines, headers

def build_table(specwidths, speclines, photwidths, photlines, specheaders, photheaders):

    headers = np.hstack((specheaders, photheaders))
    widths = np.hstack((specwidths, photwidths))
    lines = np.hstack((speclines, photlines))

    for ii, width in enumerate(widths):
        if ii == len(widths)-1:
            print(''.join(np.repeat('=', width)))
        else:
            print(''.join(np.repeat('=', width))+' ', end='')            
            
    for ii, (width, dd) in enumerate(zip(widths, headers)):
        if ii == len(widths)-1:
            print(str.ljust(dd, width))
        else:
            print(str.ljust(dd, width)+' ', end='')
    
    for ii, width in enumerate(widths):
        if ii == len(widths)-1:
            print(''.join(np.repeat('=', width)))
        else:
            print(''.join(np.repeat('=', width))+' ', end='')
            
    for line in lines:
        for ii, (width, dd) in enumerate(zip(widths, line)):
            if ii == len(widths)-1:
                print(str.ljust(dd, width))
            else:
                print(str.ljust(dd, width)+' ', end='')
                
    for ii, width in enumerate(widths):
        if ii == len(widths)-1:
            print(''.join(np.repeat('=', width)))
        else:
            print(''.join(np.repeat('=', width))+' ', end='')            

def main():

    p = argparse.ArgumentParser()
    p.add_argument('--specprod', type=str, required=True, help='output file prefix')
    p.add_argument('--mp', type=int, default=1, help='number of multiprocessing cores')
    p.add_argument('--statistics', action='store_true', help='Do file statistics.')
    p.add_argument('--validate', action='store_true', help='Validate the files.')
    
    args = p.parse_args()

    outdir = '/global/cfs/cdirs/desi/spectro/fastspecfit/'+args.specprod
    desi_root = os.environ.get('DESI_ROOT', DESI_ROOT_NERSC)
    specprod_dir = os.path.join(desi_root, 'spectro', 'redux', args.specprod)

    if args.specprod == 'guadalupe':
        sortbyrows = True
    else:
        sortbyrows = False

    # Do statistics.
    if args.statistics:
        # by survey
        fastspecfiles = np.hstack((sorted(glob(os.path.join(outdir, 'catalogs', 'fastspec-{}-*.fits'.format(args.specprod)))),
                                   os.path.join(outdir, 'catalogs', 'fastspec-{}.fits'.format(args.specprod))))
        fastphotfiles = np.hstack((sorted(glob(os.path.join(outdir, 'catalogs', 'fastphot-{}-*.fits'.format(args.specprod)))),
                                   os.path.join(outdir, 'catalogs', 'fastphot-{}.fits'.format(args.specprod))))
        #fastspecfiles = np.array(sorted(glob(os.path.join(outdir, 'catalogs', 'fastspec-{}-*.fits'.format(args.specprod)))))
        #fastphotfiles = np.array(sorted(glob(os.path.join(outdir, 'catalogs', 'fastphot-{}-*.fits'.format(args.specprod)))))
        specwidths, speclines, specheaders = fileinfo(fastspecfiles, sortbyrows=sortbyrows)
        photwidths, photlines, photheaders = fileinfo(fastphotfiles, sortbyrows=sortbyrows)
        build_table(specwidths, speclines, photwidths, photlines, specheaders, photheaders)

    # Validate files.
    if args.validate:

        # Read all the zpix catalogs in parallel.
        zcatfiles = glob(os.path.join(specprod_dir, 'zcatalog', 'zpix-*-*.fits'))
        mpargs = []
        for zcatfile in zcatfiles:
            mpargs.append([zcatfile, args.specprod])
        if args.mp > 1:
            with multiprocessing.Pool(args.mp) as P:
                P.map(_check_one_catalog, mpargs)
        else:
            [check_one_catalog(*mparg) for mparg in mpargs]

        pdb.set_trace()
        
        for survey in surveys:
        #for survey in ['sv1']:
            print('Working on survey {}'.format(survey))
            obsfile = os.path.join(args.outdir, 'observed-targets', 'targetphot-{}-{}.fits'.format(survey, args.specprod))
            potfile = os.path.join(args.outdir, 'potential-targets', 'targetphot-potential-{}-{}.fits'.format(survey, args.specprod))
            obs = Table(fitsio.read(obsfile))
            print('Read {:,d} objects from {}'.format(len(obs), obsfile))
            pot = Table(fitsio.read(potfile))
            print('Read {:,d} objects from {}'.format(len(pot), potfile))

            #obs = obs[obs['TILEID'] == 80870]

            tileids = sorted(set(obs['TILEID']))
            print('Processing {} unique tiles'.format(len(tileids)))
            
            # Multiprocess over tiles
            mpargs = [[tileid, obs[obs['TILEID'] == tileid], pot[pot['TILEID'] == tileid]] for tileid in tileids]
                
            if args.mp > 1:
                with multiprocessing.Pool(args.mp) as P:
                    P.map(_targets_one_tile, mpargs)
            else:
                [targets_one_tile(*mparg) for mparg in mpargs]
        print()
            
if __name__ == '__main__':
    main()
